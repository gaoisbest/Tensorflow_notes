{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this series (includes three parts), I focus on text classification task based on Recurrent Neural Networks (RNNs). From part 1 to part 3, I will add more concepts to deal with more sophisticated scenarios gradually.\n",
    "\n",
    "If you are not familiar with concepts of RNNs, the following list gives popular tutorials about RNNs:\n",
    "- Christopher Olah's [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
    "- Andrej Karpathy's [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
    "- R2RT's [Recurrent Neural Networks in Tensorflow I II III](https://r2rt.com/recurrent-neural-networks-in-tensorflow-i.html)\n",
    "- Danijar Hafner's [Introduction to Recurrent Networks in TensorFlow](https://danijar.com/introduction-to-recurrent-networks-in-tensorflow)\n",
    "- Denny Britz's [Recurrent Neural Networks Tutorial, Part 1 – Introduction to RNNs](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/)\n",
    "\n",
    "The example data used in this series is from [Sogou](http://www.sogou.com/labs/resource/cs.php) corpus. I have downloaded the data, performed duplicates removing, Chinese word segmentation, stopwords removing etc. The example data used here includes six categories, i.e, `{1:auto, 2:business, 3: it, 4:health; 5:sports, 6:yule}`. Each category includes `training_x.cs` (contains `15,000` articles) and `testing_x.cs` (contains `3,000` articles). You can download the data from [here](http://pan.baidu.com/s/1hs27uHA).\n",
    "\n",
    "Core concepts in part 1:\n",
    "- One layer RNNs, which includes **three cell types**: `tf.contrib.rnn.BasicRNNCell`, `tf.contrib.rnn.BasicLSTMCell` and `tf.contrib.rnn.GRUCell`, are used. \n",
    "- The length of input sequences (means articles here) is **fixed**. \n",
    "- The inputs and outputs of `outputs, last_state = tf.contrib.rnn.static_rnn(cell, inputs)` are a **list**. \n",
    "- **`outputs[-1]`** means the output at last time step. `outputs[-1]` is focused since we only interests on the output of RNNs at last time step for classification task.\n",
    "- For one layer RNNs, **`outputs[-1] == last_state`** for `BasicLSTMCell` and `GRUCell`. **`output[-1] == last_state.h`** for `BasicLSTMCell`. Why ? See below.\n",
    "- Two `tf.summary.FileWriter` are initialized to save `accuracy` and `loss` of both **training** and **testing** steps to TensorBoard.\n",
    "- Tensorflow model architecture (followed from [here](https://danijar.com/structuring-your-tensorflow-models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import codecs\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from random import shuffle\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class `DataGenerator` is used to read input files, convert words to index and generate batch training or testing data. \n",
    "\n",
    "Since the RNNs input has fixed length. Longer sequences are truncated to `Arguments.MAX_SEQ_LENGTH` and shorter sequences are padded to `Arguments.MAX_SEQ_LENGTH`. \n",
    "\n",
    "Two extra word are introduced, `PAD` for padding shorter sequences and `OOV` for representing out-of-vocabulary words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataGenerator():\n",
    "    \"\"\"\n",
    "    reading each training and testing files, and generating batch data.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, args):\n",
    "        self.folder_path = args.FOLDER_PATH\n",
    "        self.batch_size = args.BATCH_SIZE\n",
    "        self.vocab_size = args.VOCAB_SIZE\n",
    "        self.max_seq_len = args.MAX_SEQ_LENGTH\n",
    "        self.num_epoch = args.NUM_EPOCH\n",
    "        self.read_build_input()\n",
    "        self.single_generator_training = self.generate_sample_training()\n",
    "        self.single_generator_testing = self.generate_sample_testing()\n",
    "        self.label_dict = {0:'auto', 1:'business', 2:'IT', 3:'health', 4:'sports', 5:'yule'}\n",
    "        \n",
    "        \n",
    "    def read_build_input(self):\n",
    "        training_src = []\n",
    "        testing_src = []\n",
    "        article_len = []\n",
    "\n",
    "        for cur_category in range(1, 7):\n",
    "            \n",
    "            print('parsing file >>>>>>>>>>>>>>> ', cur_category)\n",
    "            print('-'*100)\n",
    "            \n",
    "            training_input_file = codecs.open(filename=os.path.join(self.folder_path, 'training_' + str(cur_category) + '.cs'), mode='r', encoding='utf-8')\n",
    "            for tmp_line in training_input_file:\n",
    "                training_src.append((tmp_line.split(), cur_category-1))\n",
    "                article_len.append(len(tmp_line.split()))\n",
    "\n",
    "            testing_input_file = codecs.open(filename=os.path.join(self.folder_path, 'testing_' + str(cur_category) + '.cs'), mode='r', encoding='utf-8')\n",
    "            for tmp_line in testing_input_file:\n",
    "                testing_src.append((tmp_line.split(), cur_category-1))\n",
    "                article_len.append(len(tmp_line.split()))\n",
    "\n",
    "        shuffle(training_src)\n",
    "        shuffle(testing_src)\n",
    "        \n",
    "        assert(len(article_len) == (len(training_src) + len(testing_src)))\n",
    "        print('='*100)\n",
    "        print('Size of training data:', len(training_src))\n",
    "        print('Size of testing data:', len(testing_src))\n",
    "        print('Average length of all articles', sum(article_len)/len(article_len))\n",
    "    \n",
    "        self.TRAINING_SIZE = len(training_src)\n",
    "        args.TESTING_SIZE = len(testing_src)\n",
    "        \n",
    "        training_X_src = [pair[0] for pair in training_src]\n",
    "        testing_X_src = [pair[0] for pair in testing_src]\n",
    "        all_data = list(itertools.chain.from_iterable(training_X_src + testing_X_src))\n",
    "        word_counter = Counter(all_data).most_common(self.vocab_size)\n",
    "        del all_data\n",
    "        \n",
    "        print('='*100)\n",
    "        print('top 10 frequent words:')\n",
    "        print(word_counter[0:10])\n",
    "        self.word2idx = {val[0]: idx+1 for idx, val in enumerate(word_counter)}\n",
    "        self.word2idx['PAD'] = 0 # padding word\n",
    "        self.word2idx['OOV'] = self.vocab_size + 1 # out-of-vocabulary\n",
    "        self.idx2word = dict(zip(self.word2idx.values(), self.word2idx.keys()))\n",
    "        print('Total vocabulary size:{}'.format(len(self.word2idx)))\n",
    "        \n",
    "        self.training = [([self.word2idx[w] if w in self.word2idx else self.word2idx['OOV'] for w in tmp_pair[0][0:self.max_seq_len]], tmp_pair[1]) for tmp_pair in training_src]\n",
    "        self.testing_ori =  [([self.word2idx[w] if w in self.word2idx else self.word2idx['OOV'] for w in tmp_pair[0][0:self.max_seq_len]], tmp_pair[1]) for tmp_pair in testing_src]\n",
    "        self.testing = [(tmp_pair[0] + [self.word2idx['PAD']] * (self.max_seq_len - len(tmp_pair[0])), tmp_pair[1]) if len(tmp_pair[0]) < self.max_seq_len else tmp_pair for tmp_pair in self.testing_ori]\n",
    "    \n",
    "    def generate_sample_training(self):\n",
    "        \"\"\"\n",
    "        If len(each article) < self.max_seq_len:\n",
    "            padding them with 0\n",
    "        else:\n",
    "            truncating them to self.max_seq_len\n",
    "        \"\"\"\n",
    "        outer_index = 0\n",
    "        for X_y_pair in itertools.cycle(self.training):  # infinite loop each article\n",
    "            tmp_input_len = len(X_y_pair[0])\n",
    "            if tmp_input_len < self.max_seq_len:\n",
    "                input_X = X_y_pair[0] + [self.word2idx['PAD']] * (self.max_seq_len - tmp_input_len)\n",
    "            else:\n",
    "                input_X = X_y_pair[0]\n",
    "            \n",
    "            output_y = X_y_pair[1]\n",
    "            if outer_index in [0, self.batch_size-1]:\n",
    "                print('='*100)\n",
    "                print('Training text:', ' '.join([self.idx2word[tmp_id] for tmp_id in input_X]))\n",
    "                print('Training text length:', len(input_X))\n",
    "                print('Training label:', self.label_dict[output_y])\n",
    "                \n",
    "            yield input_X, output_y\n",
    "            outer_index += 1\n",
    "    \n",
    "    def generate_sample_testing(self):\n",
    "        \"\"\"\n",
    "        If len(each article) < self.max_seq_len:\n",
    "            padding them with 0\n",
    "        else:\n",
    "            truncating them to self.max_seq_len\n",
    "        \"\"\"\n",
    "        outer_index = 0\n",
    "        for X_y_pair in itertools.cycle(self.testing):  # infinite loop each article\n",
    "            tmp_input_len = len(X_y_pair[0])\n",
    "            if tmp_input_len < self.max_seq_len:\n",
    "                input_X = X_y_pair[0] + [self.word2idx['PAD']] * (self.max_seq_len - tmp_input_len)\n",
    "            else:\n",
    "                input_X = X_y_pair[0]\n",
    "            \n",
    "            output_y = X_y_pair[1]\n",
    "            if outer_index in [0, self.batch_size-1]:\n",
    "                print('='*100)\n",
    "                print('Testing text:', ' '.join([self.idx2word[tmp_id] for tmp_id in input_X]))\n",
    "                print('Testing text length:', len(input_X))\n",
    "                print('Testing label:', self.label_dict[output_y])\n",
    "                \n",
    "            yield input_X, output_y\n",
    "            outer_index += 1\n",
    "        \n",
    "\n",
    "    def next_batch_training(self):\n",
    "        input_X_batch = []\n",
    "        output_y_batch = []\n",
    "        for idx in range(self.batch_size):\n",
    "            tmp_X, tmp_y = next(self.single_generator_training)\n",
    "            input_X_batch.append(tmp_X)\n",
    "            output_y_batch.append(tmp_y)\n",
    "        return np.array(input_X_batch, dtype=np.int32), np.array(output_y_batch, dtype=np.int32)\n",
    "    \n",
    "    def next_testing(self):\n",
    "        testing_X = np.array([tmp_pair[0] for tmp_pair in self.testing], dtype=np.int32)\n",
    "        testing_y = np.array([tmp_pair[1] for tmp_pair in self.testing], dtype=np.int32)\n",
    "        return testing_X, testing_y        \n",
    "    \n",
    "    def next_batch_testing(self):\n",
    "        input_X_batch = []\n",
    "        output_y_batch = []\n",
    "        for idx in range(self.batch_size):\n",
    "            tmp_X, tmp_y = next(self.single_generator_testing)\n",
    "            input_X_batch.append(tmp_X)\n",
    "            output_y_batch.append(tmp_y)\n",
    "        return np.array(input_X_batch, dtype=np.int32), np.array(output_y_batch, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper-parameters for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Arguments:\n",
    "    \"\"\"\n",
    "    main hyper-parameters\n",
    "    \"\"\"\n",
    "    MAX_SEQ_LENGTH = 150 # since Average length of all articles around 143\n",
    "    EMBED_SIZE = 128 # embedding dimensions\n",
    "    BATCH_SIZE = 64\n",
    "    VOCAB_SIZE = 300000 # vocabulary size\n",
    "    NUM_CLASSES = 6 # number of classes\n",
    "    FOLDER_PATH = 'sogou_corpus'\n",
    "    NUM_EPOCH = 7\n",
    "    RNN_TYPE = 'LSTM' # RNN, LSTM or GRU\n",
    "    CHECKPOINTS_DIR = 'text_classification_LSTM_model'\n",
    "    LOGDIR = 'text_classification_LSTM_logdir'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function for better organizing Tensorflow model structure.\n",
    "\n",
    "From https://danijar.com/structuring-your-tensorflow-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "def lazy_property(function):\n",
    "    \"\"\"\n",
    "    helper function from https://danijar.com/structuring-your-tensorflow-models\n",
    "    \"\"\"\n",
    "    attribute = '_cache_' + function.__name__\n",
    "\n",
    "    @property\n",
    "    @functools.wraps(function)\n",
    "    def decorator(self):\n",
    "        if not hasattr(self, attribute):\n",
    "            setattr(self, attribute, function(self))\n",
    "        return getattr(self, attribute)\n",
    "\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `outputs, last_state = tf.contrib.rnn.static_rnn(cell, inputs, initial_state)`\n",
    "\n",
    "`inputs` is a `list`, which size is `num_steps` and shape of each element is `[batch_size, num_units]`.\n",
    "\n",
    "`outputs` is a `list`, which size is `num_steps` and contains the output (i.e., `ht`) at each time step.\n",
    "\n",
    "Let `ht` and `ct` be the hidden state and cell state at time step *t*, respectively.\n",
    "\n",
    "`last_state` is a `Tensor`, a tuple of `Tensor`, a `LSTMStateTuple` or a tuple of `LSTMStateTuple` in different scenarios.\n",
    "\n",
    "### For `BasicRNNCell` and `GRUCell`\n",
    "- one layer\n",
    "    - Both `outputs[-1]` and `last_state` are `ht` at last time step\n",
    "    - **`outputs[-1] == last_state`**\n",
    "    - For instance: \n",
    "    ```\n",
    "    BasicRNNCell:\n",
    "    outputs[-1]: \n",
    "    Tensor(\"model/rnn/rnn/basic_rnn_cell/Tanh_199:0\", shape=(32, 128), dtype=float32)    \n",
    "    last_state: \n",
    "    Tensor(\"model/rnn/rnn/basic_rnn_cell/Tanh_199:0\", shape=(32, 128), dtype=float32)\n",
    "    \n",
    "    GRUCell:\n",
    "    outputs[-1]:\n",
    "    Tensor(\"model/rnn/rnn/gru_cell/add_199:0\", shape=(32, 128), dtype=float32)\n",
    "    last_state:\n",
    "    Tensor(\"model/rnn/rnn/gru_cell/add_199:0\", shape=(32, 128), dtype=float32)\n",
    "    ```\n",
    "- Multiple layers (with `tf.contrib.rnn.MultiRNNCell` wrapper)\n",
    "    - `outputs[-1]` is `ht` of **top** layer at the last time step\n",
    "    - `last_state` contains `ht` of **all** layers at last time step\n",
    "    - **`outputs[-1] == last_state[len(last_state)-1]`**\n",
    "    - For instance (with `2` layers):\n",
    "    ```\n",
    "    outputs[-1]: \n",
    "    Tensor(\"model/rnn/rnn/multi_rnn_cell/cell_0/cell_0/basic_rnn_cell/Tanh_399:0\", shape=(32, 128), dtype=float32)\n",
    "    \n",
    "    last_state: \n",
    "    (<tf.Tensor 'model/rnn/rnn/multi_rnn_cell/cell_0/cell_0/basic_rnn_cell/Tanh_398:0' shape=(32, 128) dtype=float32>,\n",
    "    <tf.Tensor 'model/rnn/rnn/multi_rnn_cell/cell_0/cell_0/basic_rnn_cell/Tanh_399:0' shape=(32, 128) dtype=float32>)\n",
    "    ```\n",
    "\n",
    "### For `BasicLSTMCell`\n",
    "- One layer\n",
    "    - `outputs[-1]` is `ht` at last time step\n",
    "    - `last_state` is `LSTMStateTuple(ct, ht)` at last time step\n",
    "    - **`outputs[-1] == last_state.h`**\n",
    "    - For instance:\n",
    "    ```\n",
    "    outputs[-1]:\n",
    "    Tensor(\"model/rnn/rnn/basic_lstm_cell/mul_599:0\", shape=(32, 128), dtype=float32)\n",
    "\n",
    "    last_state: \n",
    "    LSTMStateTuple(c=<tf.Tensor 'model/rnn/rnn/basic_lstm_cell/add_399:0' shape=(32, 128) dtype=float32>, h=<tf.Tensor 'model/rnn/rnn/basic_lstm_cell/mul_599:0' shape=(32, 128) dtype=float32>)\n",
    "    ```\n",
    "- Multiple layers (with `tf.contrib.rnn.MultiRNNCell` wrapper)\n",
    "    - `outputs[-1]` is `ht` of **top** layer at the last time step\n",
    "    - `last_state` contains `LSTMStateTuple(ct, ht)` of **all** layers at last time step\n",
    "    - **`outputs[-1] == last_state[len(last_state)-1].h`**\n",
    "    - For instance (with `4` layers):\n",
    "    ```\n",
    "    outputs[-1]:\n",
    "    Tensor(\"model/rnn/rnn/multi_rnn_cell/cell_0/cell_0/basic_lstm_cell/mul_2399:0\", shape=(32, 128), dtype=float32)\n",
    "    \n",
    "    last_state: \n",
    "    (LSTMStateTuple(c=<tf.Tensor 'model/rnn/rnn/multi_rnn_cell/cell_0/cell_0/basic_lstm_cell/add_1593:0' shape=(32, 128) dtype=float32>, h=<tf.Tensor 'model/rnn/rnn/multi_rnn_cell/cell_0/cell_0/basic_lstm_cell/mul_2390:0' shape=(32, 128) dtype=float32>), \n",
    "    LSTMStateTuple(c=<tf.Tensor 'model/rnn/rnn/multi_rnn_cell/cell_0/cell_0/basic_lstm_cell/add_1595:0' shape=(32, 128) dtype=float32>, h=<tf.Tensor 'model/rnn/rnn/multi_rnn_cell/cell_0/cell_0/basic_lstm_cell/mul_2393:0' shape=(32, 128) dtype=float32>), \n",
    "    LSTMStateTuple(c=<tf.Tensor 'model/rnn/rnn/multi_rnn_cell/cell_0/cell_0/basic_lstm_cell/add_1597:0' shape=(32, 128) dtype=float32>, h=<tf.Tensor 'model/rnn/rnn/multi_rnn_cell/cell_0/cell_0/basic_lstm_cell/mul_2396:0' shape=(32, 128) dtype=float32>), \n",
    "    LSTMStateTuple(c=<tf.Tensor 'model/rnn/rnn/multi_rnn_cell/cell_0/cell_0/basic_lstm_cell/add_1599:0' shape=(32, 128) dtype=float32>, h=<tf.Tensor 'model/rnn/rnn/multi_rnn_cell/cell_0/cell_0/basic_lstm_cell/mul_2399:0' shape=(32, 128) dtype=float32>))\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TextClassificationModel:\n",
    "    \"\"\"\n",
    "    Model class.\n",
    "    \"\"\"\n",
    "    def __init__(self, args, is_training=True):\n",
    "        self.num_units = args.EMBED_SIZE\n",
    "        self.batch_size = args.BATCH_SIZE\n",
    "        self.rnn_type = args.RNN_TYPE\n",
    "        self.is_training = is_training\n",
    "        \n",
    "        if self.is_training:\n",
    "            self.batch_size = args.BATCH_SIZE\n",
    "        else:\n",
    "            self.batch_size = args.TESTING_SIZE\n",
    "        \n",
    "        self.num_classes = args.NUM_CLASSES\n",
    "        self.vocab_size = args.VOCAB_SIZE + 2\n",
    "        self.num_steps = args.MAX_SEQ_LENGTH\n",
    "        self.global_step = tf.Variable(initial_value=0, dtype=tf.int32, trainable=False, name='global_step')\n",
    "\n",
    "        self.input_output\n",
    "        self.model\n",
    "        self.score\n",
    "        self.cost\n",
    "        self.optimizer\n",
    "        \n",
    "    @lazy_property\n",
    "    def input_output(self):\n",
    "        with tf.name_scope('input_output'):\n",
    "            input_X = tf.placeholder(dtype=tf.int32, shape=[self.batch_size, self.num_steps], name='input_X')\n",
    "            output_y = tf.placeholder(dtype=tf.int32, shape = [self.batch_size], name='output_y')\n",
    "        return (input_X, output_y)\n",
    "                \n",
    "        \n",
    "    @lazy_property\n",
    "    def model(self):\n",
    "        \n",
    "        with tf.name_scope('RNNs_model'):\n",
    "            with tf.variable_scope('embedding'):\n",
    "                with tf.device('/cpu:0'):\n",
    "                    embedding_matrix = tf.get_variable(name='embedding_matrix', shape=[self.vocab_size, self.num_units])\n",
    "                    # inputs shape: (self.batch_size, self.num_steps, self.num_units)\n",
    "                    inputs = tf.nn.embedding_lookup(params=embedding_matrix, ids=self.input_output[0], name='embed')\n",
    "\n",
    "            if self.rnn_type == 'RNN':\n",
    "                cell = tf.contrib.rnn.BasicRNNCell(num_units=self.num_units)\n",
    "            elif self.rnn_type == 'GRU':\n",
    "                cell = tf.contrib.rnn.GRUCell(num_units=self.num_units)\n",
    "            elif self.rnn_type == 'LSTM':\n",
    "                cell = tf.contrib.rnn.BasicLSTMCell(num_units=self.num_units)\n",
    "            else:\n",
    "                raise ValueError('The input rnn type is undefined.')\n",
    "                \n",
    "            initial_state = cell.zero_state(batch_size=self.batch_size, dtype=tf.float32)            \n",
    "           \n",
    "            inputs = tf.unstack(inputs, self.num_steps, 1)            \n",
    "            \n",
    "            print('='*100)\n",
    "            print('static_rnn inputs type:', type(inputs)) # list\n",
    "            print('static_rnn inputs len:', len(inputs)) # self.num_steps\n",
    "            print('static_rnn inputs element type:', type(inputs[0])) # Tensor\n",
    "            print('static_rnn inputs element shape:', inputs[0].get_shape()) # [self.batch_size, self.num_units]\n",
    "            print('='*100)\n",
    "\n",
    "\n",
    "            outputs, last_state = tf.contrib.rnn.static_rnn(cell, inputs=inputs, initial_state=initial_state)\n",
    "            \n",
    "            print('static_rnn output type:', type(outputs)) # list\n",
    "            print('static_rnn output length:', len(outputs)) # self.num_steps\n",
    "            print('static_rnn output element type:', type(outputs[-1])) # Tensor, output[-1] is last hidden state (i.e., hidden state at (self.num_steps - 1))\n",
    "            print('static_rnn output element shape:', outputs[-1].get_shape()) # [self.batch_size, self.num_units]                \n",
    "            print('static_rnn last_state type:', type(last_state))  # LSTMStateTuple (for BasicLSTMCell) or Tensor (for BasicRNNCell or GRUCell) \n",
    "            print('last_state:', last_state)\n",
    "            print('='*100)\n",
    "            \n",
    "            if self.rnn_type == 'RNN' or self.rnn_type == 'GRU':\n",
    "                print('outputs[-1] == last_state', outputs[-1] == last_state)\n",
    "            elif self.rnn_type == 'LSTM':\n",
    "                print('outputs[-1] == last_state.h', outputs[-1] == last_state.h)\n",
    "            else:\n",
    "                raise ValueError('The input rnn type is undefined.')\n",
    "\n",
    "        return (outputs, last_state)\n",
    "    \n",
    "    @lazy_property\n",
    "    def score(self):\n",
    "        \n",
    "        with tf.variable_scope('score'):\n",
    "\n",
    "            softmax_weights = tf.get_variable(name='softmax_weights', shape=[self.num_units, self.num_classes])\n",
    "            softmax_bias = tf.get_variable(name='softmax_bias', shape=[self.num_classes])\n",
    "            logits = tf.matmul(self.model[0][-1], softmax_weights) + softmax_bias\n",
    "            probs = tf.nn.softmax(logits)\n",
    "            prediction = tf.argmax(probs, 1)\n",
    "            accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.cast(prediction, tf.int32), self.input_output[1]), tf.float32))\n",
    "            tf.summary.scalar(name='accuracy', tensor=accuracy)\n",
    "            \n",
    "        return (logits, accuracy, prediction)\n",
    "    \n",
    "    @lazy_property\n",
    "    def cost(self):        \n",
    "            \n",
    "        with tf.name_scope('cost'):\n",
    "            cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=self.score[0], labels=self.input_output[1]))\n",
    "            tf.summary.scalar(name='loss', tensor=cost)\n",
    "            tf.summary.histogram(name='histogram_loss', values=cost)\n",
    "            self.summary_op = tf.summary.merge_all()\n",
    "        return cost\n",
    "    \n",
    "    \n",
    "    @lazy_property\n",
    "    def optimizer(self):\n",
    "        with tf.name_scope('optimizer'):\n",
    "            return tf.train.AdamOptimizer(learning_rate=0.01).minimize(loss=self.cost, global_step=self.global_step)\n",
    "                           \n",
    "                \n",
    "    def predict(self, sess, data):\n",
    "        testing_X = np.array([tmp_pair[0] for tmp_pair in data.testing], dtype=np.int32)\n",
    "        testing_y = np.array([tmp_pair[1] for tmp_pair in data.testing], dtype=np.int32)\n",
    "        feed_dict = {model.input_output:(testing_X, testing_y)}\n",
    "        predict_labels, predict_accuracy = sess.run([model.score[2], model.score[1]], feed_dict=feed_dict)\n",
    "        print('============================Example of predictions============================')\n",
    "        for i in range(10):\n",
    "            print('-'*100)\n",
    "            print('Article: ', ''.join([data.idx2word[idx] for idx in testing_X[i]]))\n",
    "            print('Real category: ', data.label_dict[testing_y[i]])\n",
    "            print('Predicted category: ', data.label_dict[predict_labels[i]])\n",
    "            print('-'*100 + '\\n')\n",
    "        return predict_labels, predict_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train` method to train model.\n",
    "\n",
    "`train_writer` and `test_writer` used as indicator of `accuracy` and `loss` for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(data, model, args):\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        train_writer = tf.summary.FileWriter(logdir=args.LOGDIR + '/train', graph=sess.graph)\n",
    "        test_writer = tf.summary.FileWriter(logdir=args.LOGDIR + '/test')\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        ckpt = tf.train.get_checkpoint_state(checkpoint_dir=args.CHECKPOINTS_DIR)\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            saver.restore(sess=sess, save_path=ckpt.model_checkpoint_path)\n",
    "            print(ckpt)\n",
    "        \n",
    "        max_iteration_num = args.NUM_EPOCH * data.TRAINING_SIZE // args.BATCH_SIZE\n",
    "        initial_step = model.global_step.eval()\n",
    "        for idx in range(initial_step, max_iteration_num):\n",
    "            batch_X, batch_y = data.next_batch_training()\n",
    "            \n",
    "            feed_dict = {model.input_output: (batch_X, batch_y)}\n",
    "            tmp_accuracy, tmp_cost, _, tmp_summary = sess.run([model.score[1], model.cost, model.optimizer, model.summary_op], feed_dict=feed_dict)\n",
    "            train_writer.add_summary(summary=tmp_summary, global_step=model.global_step.eval())\n",
    "            \n",
    "            if idx % 50 == 0:\n",
    "                print('='*100)\n",
    "                print('Step:{}, training accuracy:{:4f}'.format(model.global_step.eval(), tmp_accuracy))\n",
    "                print('Step: {} / {}, loss:{:4f}, accuracy:{:4f}'.format(idx, max_iteration_num, tmp_cost, tmp_accuracy))\n",
    "                print('='*100)\n",
    "                \n",
    "            if idx % 200 == 0:\n",
    "                test_batch_X, test_batch_y = data.next_batch_testing()\n",
    "                test_feed_dict = {model.input_output:(test_batch_X, test_batch_y)}\n",
    "                test_tmp_cost, test_tmp_accuracy, test_tmp_summary = sess.run([model.cost, model.score[1], model.summary_op], feed_dict=test_feed_dict)\n",
    "                test_writer.add_summary(summary=test_tmp_summary, global_step=model.global_step.eval())\n",
    "                print('-'*100)\n",
    "                print('Step:{}, testing accuracy:{:4f}'.format(model.global_step.eval(), test_tmp_accuracy))\n",
    "                print('Step: {} / {}, loss:{:4f}, accuracy:{:4f}'.format(idx, max_iteration_num, test_tmp_cost, test_tmp_accuracy))\n",
    "                print('-'*100)\n",
    "            \n",
    "            if idx % 500 == 0 or (idx+1) == max_iteration_num:\n",
    "                saver.save(sess=sess, save_path=os.path.join(args.CHECKPOINTS_DIR, 'text_classification_lstm.ckpt'), global_step=model.global_step.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`test` method to load the trained model and test model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(data, model, args):\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        ckpt = tf.train.latest_checkpoint(args.CHECKPOINTS_DIR)\n",
    "        print(ckpt)\n",
    "        saver.restore(sess=sess, save_path=ckpt)\n",
    "        predict_labels, predict_accuracy = model.predict(sess, data)\n",
    "        print('predict_accuracy:{:5f}'.format(predict_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing file >>>>>>>>>>>>>>>  1\n",
      "----------------------------------------------------------------------------------------------------\n",
      "parsing file >>>>>>>>>>>>>>>  2\n",
      "----------------------------------------------------------------------------------------------------\n",
      "parsing file >>>>>>>>>>>>>>>  3\n",
      "----------------------------------------------------------------------------------------------------\n",
      "parsing file >>>>>>>>>>>>>>>  4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "parsing file >>>>>>>>>>>>>>>  5\n",
      "----------------------------------------------------------------------------------------------------\n",
      "parsing file >>>>>>>>>>>>>>>  6\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Size of training data: 90000\n",
      "Size of testing data: 18000\n",
      "Average length of all articles 143.20944444444444\n",
      "====================================================================================================\n",
      "top 10 frequent words:\n",
      "[('系列', 106280), ('月', 93600), ('中', 84580), ('年', 77816), ('产品', 74051), ('日', 69792), ('英寸', 69460), ('华硕', 67137), ('屏幕尺寸', 63511), ('主频', 63027)]\n",
      "Total vocabulary size:300002\n",
      "====================================================================================================\n",
      "static_rnn inputs type: <class 'list'>\n",
      "static_rnn inputs len: 150\n",
      "static_rnn inputs element type: <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "static_rnn inputs element shape: (64, 128)\n",
      "====================================================================================================\n",
      "static_rnn output type: <class 'list'>\n",
      "static_rnn output length: 150\n",
      "static_rnn output element type: <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "static_rnn output element shape: (64, 128)\n",
      "static_rnn last_state type: <class 'tensorflow.python.ops.rnn_cell_impl.LSTMStateTuple'>\n",
      "last_state: LSTMStateTuple(c=<tf.Tensor 'RNNs_model/rnn/rnn/basic_lstm_cell/add_299:0' shape=(64, 128) dtype=float32>, h=<tf.Tensor 'RNNs_model/rnn/rnn/basic_lstm_cell/mul_449:0' shape=(64, 128) dtype=float32>)\n",
      "====================================================================================================\n",
      "outputs[-1] == last_state.h True\n",
      "====================================================================================================\n",
      "Training text: 华硕 华硕 风采 系列 华硕 系列 华硕 欣逸 系列 笔记本电脑 产品 搜索 每页 项 屏幕尺寸 英寸 主频 内存容量 硬盘容量 显卡 芯片 高性能 图形 加速 芯 暂无 屏幕尺寸 英寸 主频 内存容量 硬盘容量 显卡 芯片 笔记本 重量 有线 网卡 多参数 暂无 屏幕尺寸 英寸 主频 内存容量 硬盘容量 显卡 芯片 笔记本 重量 有线 网卡 多参数 暂无 屏幕尺寸 英寸 主频 内存容量 硬盘容量 显卡 芯片 电视 输出 暂无 屏幕尺寸 英寸 主频 内存容量 硬盘容量 显卡 芯片 电视 输出 操作系统 暂无 屏幕尺寸 英寸 主频 内存容量 硬盘容量 显卡 芯片 暂无 屏幕尺寸 英寸 主频 内存容量 硬盘容量 显卡 芯片 支持 笔记本 重量 暂无 屏幕尺寸 英寸 主频 内存容量 硬盘容量 显卡 芯片 操作系统 有线 网卡 多参数 暂无 屏幕尺寸 英寸 主频 内存容量 硬盘容量 显卡 芯片 支持 有线 网卡 网卡 暂无 屏幕尺寸 英寸 型号 赛扬 主频 内存容量 硬盘容量 显卡 芯片 超强 性能 图形 加速 暂无 屏幕尺寸 英寸 主频 内存容量 硬盘容量 显卡 芯片 支持 笔记本 重量 暂无 屏幕尺寸 英寸 主频 内存容量 硬盘容量 操作系统 有线 网卡 暂无\n",
      "Training text length: 150\n",
      "Training label: IT\n",
      "====================================================================================================\n",
      "Training text: 夏天 比拉诺瓦 原本 希望 一名 左后卫 中 后卫 凯塔 离队 打乱 巴萨新 帅 计划 红 蓝军团 今夏 引进 一名 中 前卫 才行 比拉诺瓦 心目 中 哈维 马丁内斯 适合 巴萨 引援 对象 巴斯克人 胜任 中卫 中 前卫 两个 位置 哈维 马丁内斯 西班牙 国家队 中 早已 巴萨 体系 出色 技战术 能力 身体 条件 加泰 帮 相处 融洽 哈维 马丁内斯 转投 一家 豪门 身价 哈维 马丁内斯 违约金 万 欧元 毕巴 高层 早已 放出 话 想要 带走 巴斯克人 球队 支付 违约金 算上 奢侈税 哈维 马丁内斯 总 身价 高达 万 欧元 西班牙 电视 三台 透露 巴萨 哈维 马丁内斯 拼 红 蓝军团 支付 违约金 巴萨 体育 主管 苏比萨雷塔 毕巴 球员 高官 巴斯克 雄狮 高层 关系 极佳 苏比萨雷塔 巴萨 万 欧元 价码 哈维 马丁内斯 税务 部门 补交 一笔 奢侈税 毕巴 拿到 这笔 钱 知足 犯不上 逼 巴萨 缴纳 奢侈税 巴萨 今夏 转会 预算 仅为 万 欧元 梦三队 阿尔巴 身上 花 万 比拉诺瓦 手头 剩下 万 欧元 想得到\n",
      "Training text length: 150\n",
      "Training label: sports\n",
      "====================================================================================================\n",
      "Step:1, training accuracy:0.187500\n",
      "Step: 0 / 9843, loss:1.862148, accuracy:0.187500\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Testing text: 月 日 上午 英伦 汽车 乔氏 杯 决战 亨德利 中式 八球 挑战赛 银川站 半决赛 方桌 谋士 台球俱乐部 展开 争夺 本轮 赛制 局 胜 马 海荣 发挥 出色 淘汰 海潮 一场 半决赛 一龙 战胜 高小龙 两人 决赛 下午 三点 准时 上演 马 海荣 海潮 比赛 安排 台 两人 实力 相差无几 马 海荣 进攻 犀利 海荣 防守 两人 球风 偏 稳健 比赛 特别 缓慢 最终 鏖战 半小时 分出 胜负 第一局 马 海荣 险些 开出 黄金 局势 佳 马 海荣 号球 沉底 防守 海潮 如法炮制 本局 进攻 权 易主 两人 防守 僵持 中 养 袋口 战略 经验 防守 海潮 占据主动 不甘 被动挨打 马 海荣 拼进 翻袋 号球 拿下 首局 第二局 第一局 走势 类似 两人 开局 比拼 防守 海潮 依然 占据主动 遗憾 一举 拿下 关头 简单 走 位 失误 到手 胜利 拱手让人 本局 输 实在 可惜 第三局 马 海荣 连续 三次 开球 比赛 陷入 胶着 简短 防守 缠斗 海潮 改变 战略 变守 攻 进攻\n",
      "Testing text length: 150\n",
      "Testing label: sports\n",
      "====================================================================================================\n",
      "Testing text: 原本 月 日 杜苏芮 大驾光临 羊城 各方 得力 杜苏芮 识趣 羊城 祥和 祥和 不到 小时 白云山 座城 遭遇 晴天霹雳 广州 限购令 突如其来 汽车 经销商 意向 购车 客户 打了个 措手不及 限牌 限购 摇号 一时间 布满 羊城 上空 哀鸿遍野 未来 一年 买辆 爱车 难以 登天 其实不然 郑州日产 广东 龙骑 店早 一批 牌 名额 摇号 购车 广东 龙骑 限购 广东 龙骑 购车 取个 靓牌 车辆 新购 增购 过户 一律 停止 现是 抢先 拥有 车牌 机会 错过 摇号 整年 抢购 热线 广东 龙骑 汽车销售 有限公司 资产 优质 实力雄厚 信誉 优良 拥有 高素质 营销 队伍 专业 高效 维修服务 团队 秉承 高质量 服务 高水平 管理 高效率 作风 经营 宗旨 专业 专注 所见 全 服务 所愿 服务 理念 全心全意 新 老客户 提供 专业 完善 用车 解决方案 专家 式 贴身 服务 广东 龙骑 汽车销售 有限公司 郑州日产汽车 全国十佳 经销商 郑州日产汽车 千台 俱乐部 成员 郑州日产汽车 全国 销售 冠军 旗下 售后服务中心 连续 数年 评为 郑州日产汽车 全国十佳 服务站 广东 龙骑 汽车销售 有限公司\n",
      "Testing text length: 150\n",
      "Testing label: auto\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:1, testing accuracy:0.234375\n",
      "Step: 0 / 9843, loss:1.817039, accuracy:0.234375\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:51, training accuracy:0.375000\n",
      "Step: 50 / 9843, loss:1.463975, accuracy:0.375000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:101, training accuracy:0.625000\n",
      "Step: 100 / 9843, loss:1.062456, accuracy:0.625000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:151, training accuracy:0.593750\n",
      "Step: 150 / 9843, loss:0.964950, accuracy:0.593750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:201, training accuracy:0.671875\n",
      "Step: 200 / 9843, loss:1.030690, accuracy:0.671875\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:201, testing accuracy:0.765625\n",
      "Step: 200 / 9843, loss:0.812504, accuracy:0.765625\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:251, training accuracy:0.843750\n",
      "Step: 250 / 9843, loss:0.451075, accuracy:0.843750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:301, training accuracy:0.843750\n",
      "Step: 300 / 9843, loss:0.568110, accuracy:0.843750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:351, training accuracy:0.953125\n",
      "Step: 350 / 9843, loss:0.129450, accuracy:0.953125\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:401, training accuracy:0.921875\n",
      "Step: 400 / 9843, loss:0.218006, accuracy:0.921875\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:401, testing accuracy:0.921875\n",
      "Step: 400 / 9843, loss:0.290276, accuracy:0.921875\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Step:451, training accuracy:0.953125\n",
      "Step: 450 / 9843, loss:0.175668, accuracy:0.953125\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:501, training accuracy:0.890625\n",
      "Step: 500 / 9843, loss:0.229552, accuracy:0.890625\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:551, training accuracy:0.906250\n",
      "Step: 550 / 9843, loss:0.321827, accuracy:0.906250\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:601, training accuracy:0.843750\n",
      "Step: 600 / 9843, loss:0.459995, accuracy:0.843750\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:601, testing accuracy:0.921875\n",
      "Step: 600 / 9843, loss:0.330818, accuracy:0.921875\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:651, training accuracy:0.906250\n",
      "Step: 650 / 9843, loss:0.512109, accuracy:0.906250\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:701, training accuracy:0.890625\n",
      "Step: 700 / 9843, loss:0.280327, accuracy:0.890625\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:751, training accuracy:0.968750\n",
      "Step: 750 / 9843, loss:0.137724, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:801, training accuracy:0.953125\n",
      "Step: 800 / 9843, loss:0.172179, accuracy:0.953125\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:801, testing accuracy:0.937500\n",
      "Step: 800 / 9843, loss:0.187004, accuracy:0.937500\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:851, training accuracy:0.921875\n",
      "Step: 850 / 9843, loss:0.231054, accuracy:0.921875\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:901, training accuracy:0.859375\n",
      "Step: 900 / 9843, loss:0.290674, accuracy:0.859375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:951, training accuracy:0.953125\n",
      "Step: 950 / 9843, loss:0.159547, accuracy:0.953125\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:1001, training accuracy:0.968750\n",
      "Step: 1000 / 9843, loss:0.100618, accuracy:0.968750\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:1001, testing accuracy:0.937500\n",
      "Step: 1000 / 9843, loss:0.153493, accuracy:0.937500\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:1051, training accuracy:0.921875\n",
      "Step: 1050 / 9843, loss:0.185538, accuracy:0.921875\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:1101, training accuracy:0.921875\n",
      "Step: 1100 / 9843, loss:0.294324, accuracy:0.921875\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:1151, training accuracy:0.937500\n",
      "Step: 1150 / 9843, loss:0.180104, accuracy:0.937500\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:1201, training accuracy:0.984375\n",
      "Step: 1200 / 9843, loss:0.110080, accuracy:0.984375\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:1201, testing accuracy:0.953125\n",
      "Step: 1200 / 9843, loss:0.183406, accuracy:0.953125\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:1251, training accuracy:0.984375\n",
      "Step: 1250 / 9843, loss:0.068017, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:1301, training accuracy:0.937500\n",
      "Step: 1300 / 9843, loss:0.220688, accuracy:0.937500\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:1351, training accuracy:1.000000\n",
      "Step: 1350 / 9843, loss:0.030034, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:1401, training accuracy:0.906250\n",
      "Step: 1400 / 9843, loss:0.238277, accuracy:0.906250\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:1401, testing accuracy:0.906250\n",
      "Step: 1400 / 9843, loss:0.255925, accuracy:0.906250\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:1451, training accuracy:0.968750\n",
      "Step: 1450 / 9843, loss:0.111364, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:1501, training accuracy:0.937500\n",
      "Step: 1500 / 9843, loss:0.123156, accuracy:0.937500\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:1551, training accuracy:0.875000\n",
      "Step: 1550 / 9843, loss:0.272953, accuracy:0.875000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:1601, training accuracy:0.968750\n",
      "Step: 1600 / 9843, loss:0.071309, accuracy:0.968750\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:1601, testing accuracy:0.968750\n",
      "Step: 1600 / 9843, loss:0.118390, accuracy:0.968750\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Step:1651, training accuracy:0.968750\n",
      "Step: 1650 / 9843, loss:0.254794, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:1701, training accuracy:0.984375\n",
      "Step: 1700 / 9843, loss:0.098473, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:1751, training accuracy:0.984375\n",
      "Step: 1750 / 9843, loss:0.063040, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:1801, training accuracy:0.953125\n",
      "Step: 1800 / 9843, loss:0.110057, accuracy:0.953125\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:1801, testing accuracy:0.968750\n",
      "Step: 1800 / 9843, loss:0.140755, accuracy:0.968750\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:1851, training accuracy:0.968750\n",
      "Step: 1850 / 9843, loss:0.187544, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:1901, training accuracy:0.953125\n",
      "Step: 1900 / 9843, loss:0.181228, accuracy:0.953125\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:1951, training accuracy:0.984375\n",
      "Step: 1950 / 9843, loss:0.097430, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:2001, training accuracy:0.937500\n",
      "Step: 2000 / 9843, loss:0.162424, accuracy:0.937500\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:2001, testing accuracy:0.968750\n",
      "Step: 2000 / 9843, loss:0.076947, accuracy:0.968750\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:2051, training accuracy:1.000000\n",
      "Step: 2050 / 9843, loss:0.027455, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:2101, training accuracy:0.968750\n",
      "Step: 2100 / 9843, loss:0.122193, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:2151, training accuracy:0.968750\n",
      "Step: 2150 / 9843, loss:0.075670, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:2201, training accuracy:0.953125\n",
      "Step: 2200 / 9843, loss:0.085999, accuracy:0.953125\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:2201, testing accuracy:0.921875\n",
      "Step: 2200 / 9843, loss:0.177943, accuracy:0.921875\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:2251, training accuracy:0.921875\n",
      "Step: 2250 / 9843, loss:0.175409, accuracy:0.921875\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:2301, training accuracy:1.000000\n",
      "Step: 2300 / 9843, loss:0.017894, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:2351, training accuracy:0.968750\n",
      "Step: 2350 / 9843, loss:0.066283, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:2401, training accuracy:1.000000\n",
      "Step: 2400 / 9843, loss:0.027181, accuracy:1.000000\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:2401, testing accuracy:0.906250\n",
      "Step: 2400 / 9843, loss:0.281384, accuracy:0.906250\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:2451, training accuracy:0.984375\n",
      "Step: 2450 / 9843, loss:0.052557, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:2501, training accuracy:0.937500\n",
      "Step: 2500 / 9843, loss:0.206861, accuracy:0.937500\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:2551, training accuracy:0.953125\n",
      "Step: 2550 / 9843, loss:0.079078, accuracy:0.953125\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:2601, training accuracy:0.921875\n",
      "Step: 2600 / 9843, loss:0.327868, accuracy:0.921875\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:2601, testing accuracy:0.937500\n",
      "Step: 2600 / 9843, loss:0.330085, accuracy:0.937500\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:2651, training accuracy:0.984375\n",
      "Step: 2650 / 9843, loss:0.047330, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:2701, training accuracy:0.968750\n",
      "Step: 2700 / 9843, loss:0.062385, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:2751, training accuracy:0.984375\n",
      "Step: 2750 / 9843, loss:0.112346, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:2801, training accuracy:0.937500\n",
      "Step: 2800 / 9843, loss:0.257556, accuracy:0.937500\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:2801, testing accuracy:0.953125\n",
      "Step: 2800 / 9843, loss:0.096623, accuracy:0.953125\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Step:2851, training accuracy:0.937500\n",
      "Step: 2850 / 9843, loss:0.210639, accuracy:0.937500\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:2901, training accuracy:0.968750\n",
      "Step: 2900 / 9843, loss:0.050754, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:2951, training accuracy:0.937500\n",
      "Step: 2950 / 9843, loss:0.173187, accuracy:0.937500\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:3001, training accuracy:0.968750\n",
      "Step: 3000 / 9843, loss:0.131826, accuracy:0.968750\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:3001, testing accuracy:0.890625\n",
      "Step: 3000 / 9843, loss:0.413092, accuracy:0.890625\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:3051, training accuracy:1.000000\n",
      "Step: 3050 / 9843, loss:0.035105, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:3101, training accuracy:1.000000\n",
      "Step: 3100 / 9843, loss:0.025751, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:3151, training accuracy:0.953125\n",
      "Step: 3150 / 9843, loss:0.161168, accuracy:0.953125\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:3201, training accuracy:0.984375\n",
      "Step: 3200 / 9843, loss:0.190967, accuracy:0.984375\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:3201, testing accuracy:0.906250\n",
      "Step: 3200 / 9843, loss:0.335011, accuracy:0.906250\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:3251, training accuracy:0.984375\n",
      "Step: 3250 / 9843, loss:0.062184, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:3301, training accuracy:0.984375\n",
      "Step: 3300 / 9843, loss:0.133340, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:3351, training accuracy:0.937500\n",
      "Step: 3350 / 9843, loss:0.128700, accuracy:0.937500\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:3401, training accuracy:0.968750\n",
      "Step: 3400 / 9843, loss:0.068126, accuracy:0.968750\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:3401, testing accuracy:0.890625\n",
      "Step: 3400 / 9843, loss:0.355429, accuracy:0.890625\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:3451, training accuracy:0.968750\n",
      "Step: 3450 / 9843, loss:0.042378, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:3501, training accuracy:0.968750\n",
      "Step: 3500 / 9843, loss:0.211188, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:3551, training accuracy:1.000000\n",
      "Step: 3550 / 9843, loss:0.023570, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:3601, training accuracy:0.968750\n",
      "Step: 3600 / 9843, loss:0.049357, accuracy:0.968750\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:3601, testing accuracy:0.937500\n",
      "Step: 3600 / 9843, loss:0.278111, accuracy:0.937500\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:3651, training accuracy:0.968750\n",
      "Step: 3650 / 9843, loss:0.067026, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:3701, training accuracy:0.984375\n",
      "Step: 3700 / 9843, loss:0.038323, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:3751, training accuracy:0.984375\n",
      "Step: 3750 / 9843, loss:0.041790, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:3801, training accuracy:0.953125\n",
      "Step: 3800 / 9843, loss:0.086820, accuracy:0.953125\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:3801, testing accuracy:0.890625\n",
      "Step: 3800 / 9843, loss:0.233992, accuracy:0.890625\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:3851, training accuracy:0.953125\n",
      "Step: 3850 / 9843, loss:0.133250, accuracy:0.953125\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:3901, training accuracy:0.968750\n",
      "Step: 3900 / 9843, loss:0.046541, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:3951, training accuracy:0.984375\n",
      "Step: 3950 / 9843, loss:0.046328, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:4001, training accuracy:0.984375\n",
      "Step: 4000 / 9843, loss:0.066155, accuracy:0.984375\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:4001, testing accuracy:0.906250\n",
      "Step: 4000 / 9843, loss:0.295888, accuracy:0.906250\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Step:4051, training accuracy:0.984375\n",
      "Step: 4050 / 9843, loss:0.091215, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:4101, training accuracy:0.968750\n",
      "Step: 4100 / 9843, loss:0.078991, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:4151, training accuracy:0.984375\n",
      "Step: 4150 / 9843, loss:0.108287, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:4201, training accuracy:0.953125\n",
      "Step: 4200 / 9843, loss:0.158832, accuracy:0.953125\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:4201, testing accuracy:0.937500\n",
      "Step: 4200 / 9843, loss:0.088754, accuracy:0.937500\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:4251, training accuracy:0.968750\n",
      "Step: 4250 / 9843, loss:0.095559, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:4301, training accuracy:1.000000\n",
      "Step: 4300 / 9843, loss:0.007672, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:4351, training accuracy:0.968750\n",
      "Step: 4350 / 9843, loss:0.138654, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:4401, training accuracy:0.984375\n",
      "Step: 4400 / 9843, loss:0.037895, accuracy:0.984375\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:4401, testing accuracy:0.968750\n",
      "Step: 4400 / 9843, loss:0.096397, accuracy:0.968750\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:4451, training accuracy:0.953125\n",
      "Step: 4450 / 9843, loss:0.091189, accuracy:0.953125\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:4501, training accuracy:0.984375\n",
      "Step: 4500 / 9843, loss:0.044449, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:4551, training accuracy:0.953125\n",
      "Step: 4550 / 9843, loss:0.149720, accuracy:0.953125\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:4601, training accuracy:0.968750\n",
      "Step: 4600 / 9843, loss:0.159117, accuracy:0.968750\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:4601, testing accuracy:0.921875\n",
      "Step: 4600 / 9843, loss:0.374052, accuracy:0.921875\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:4651, training accuracy:0.984375\n",
      "Step: 4650 / 9843, loss:0.056189, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:4701, training accuracy:1.000000\n",
      "Step: 4700 / 9843, loss:0.005589, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:4751, training accuracy:0.984375\n",
      "Step: 4750 / 9843, loss:0.022839, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:4801, training accuracy:0.968750\n",
      "Step: 4800 / 9843, loss:0.134964, accuracy:0.968750\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:4801, testing accuracy:0.953125\n",
      "Step: 4800 / 9843, loss:0.310050, accuracy:0.953125\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:4851, training accuracy:0.953125\n",
      "Step: 4850 / 9843, loss:0.098513, accuracy:0.953125\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:4901, training accuracy:0.968750\n",
      "Step: 4900 / 9843, loss:0.095833, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:4951, training accuracy:1.000000\n",
      "Step: 4950 / 9843, loss:0.006535, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:5001, training accuracy:1.000000\n",
      "Step: 5000 / 9843, loss:0.017063, accuracy:1.000000\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:5001, testing accuracy:0.984375\n",
      "Step: 5000 / 9843, loss:0.084404, accuracy:0.984375\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:5051, training accuracy:1.000000\n",
      "Step: 5050 / 9843, loss:0.005915, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:5101, training accuracy:0.968750\n",
      "Step: 5100 / 9843, loss:0.062193, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:5151, training accuracy:0.984375\n",
      "Step: 5150 / 9843, loss:0.058746, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:5201, training accuracy:0.953125\n",
      "Step: 5200 / 9843, loss:0.147170, accuracy:0.953125\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:5201, testing accuracy:0.906250\n",
      "Step: 5200 / 9843, loss:0.432924, accuracy:0.906250\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Step:5251, training accuracy:0.953125\n",
      "Step: 5250 / 9843, loss:0.117372, accuracy:0.953125\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:5301, training accuracy:0.968750\n",
      "Step: 5300 / 9843, loss:0.102250, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:5351, training accuracy:0.968750\n",
      "Step: 5350 / 9843, loss:0.176152, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:5401, training accuracy:0.984375\n",
      "Step: 5400 / 9843, loss:0.032431, accuracy:0.984375\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:5401, testing accuracy:0.937500\n",
      "Step: 5400 / 9843, loss:0.161853, accuracy:0.937500\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:5451, training accuracy:0.953125\n",
      "Step: 5450 / 9843, loss:0.092039, accuracy:0.953125\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:5501, training accuracy:1.000000\n",
      "Step: 5500 / 9843, loss:0.008989, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:5551, training accuracy:0.984375\n",
      "Step: 5550 / 9843, loss:0.105050, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:5601, training accuracy:0.937500\n",
      "Step: 5600 / 9843, loss:0.208437, accuracy:0.937500\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:5601, testing accuracy:0.937500\n",
      "Step: 5600 / 9843, loss:0.277284, accuracy:0.937500\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:5651, training accuracy:1.000000\n",
      "Step: 5650 / 9843, loss:0.009240, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:5701, training accuracy:0.968750\n",
      "Step: 5700 / 9843, loss:0.154262, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:5751, training accuracy:0.968750\n",
      "Step: 5750 / 9843, loss:0.035429, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:5801, training accuracy:0.968750\n",
      "Step: 5800 / 9843, loss:0.114810, accuracy:0.968750\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:5801, testing accuracy:0.937500\n",
      "Step: 5800 / 9843, loss:0.202443, accuracy:0.937500\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:5851, training accuracy:0.984375\n",
      "Step: 5850 / 9843, loss:0.040101, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:5901, training accuracy:1.000000\n",
      "Step: 5900 / 9843, loss:0.006253, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:5951, training accuracy:1.000000\n",
      "Step: 5950 / 9843, loss:0.034581, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:6001, training accuracy:1.000000\n",
      "Step: 6000 / 9843, loss:0.029763, accuracy:1.000000\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:6001, testing accuracy:0.937500\n",
      "Step: 6000 / 9843, loss:0.241791, accuracy:0.937500\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:6051, training accuracy:1.000000\n",
      "Step: 6050 / 9843, loss:0.002789, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:6101, training accuracy:0.984375\n",
      "Step: 6100 / 9843, loss:0.040479, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:6151, training accuracy:0.953125\n",
      "Step: 6150 / 9843, loss:0.073803, accuracy:0.953125\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:6201, training accuracy:1.000000\n",
      "Step: 6200 / 9843, loss:0.005834, accuracy:1.000000\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:6201, testing accuracy:0.921875\n",
      "Step: 6200 / 9843, loss:0.347738, accuracy:0.921875\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:6251, training accuracy:1.000000\n",
      "Step: 6250 / 9843, loss:0.008597, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:6301, training accuracy:1.000000\n",
      "Step: 6300 / 9843, loss:0.022318, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:6351, training accuracy:0.984375\n",
      "Step: 6350 / 9843, loss:0.032954, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:6401, training accuracy:0.953125\n",
      "Step: 6400 / 9843, loss:0.083447, accuracy:0.953125\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:6401, testing accuracy:0.921875\n",
      "Step: 6400 / 9843, loss:0.489436, accuracy:0.921875\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Step:6451, training accuracy:0.968750\n",
      "Step: 6450 / 9843, loss:0.030108, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:6501, training accuracy:0.984375\n",
      "Step: 6500 / 9843, loss:0.039018, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:6551, training accuracy:0.953125\n",
      "Step: 6550 / 9843, loss:0.110855, accuracy:0.953125\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:6601, training accuracy:0.984375\n",
      "Step: 6600 / 9843, loss:0.107665, accuracy:0.984375\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:6601, testing accuracy:0.937500\n",
      "Step: 6600 / 9843, loss:0.148537, accuracy:0.937500\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:6651, training accuracy:0.968750\n",
      "Step: 6650 / 9843, loss:0.088869, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:6701, training accuracy:1.000000\n",
      "Step: 6700 / 9843, loss:0.011663, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:6751, training accuracy:0.953125\n",
      "Step: 6750 / 9843, loss:0.110014, accuracy:0.953125\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:6801, training accuracy:0.984375\n",
      "Step: 6800 / 9843, loss:0.041993, accuracy:0.984375\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:6801, testing accuracy:0.921875\n",
      "Step: 6800 / 9843, loss:0.320803, accuracy:0.921875\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:6851, training accuracy:0.984375\n",
      "Step: 6850 / 9843, loss:0.081977, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:6901, training accuracy:0.984375\n",
      "Step: 6900 / 9843, loss:0.022488, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:6951, training accuracy:0.937500\n",
      "Step: 6950 / 9843, loss:0.192615, accuracy:0.937500\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:7001, training accuracy:0.968750\n",
      "Step: 7000 / 9843, loss:0.079074, accuracy:0.968750\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:7001, testing accuracy:0.937500\n",
      "Step: 7000 / 9843, loss:0.215075, accuracy:0.937500\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:7051, training accuracy:0.984375\n",
      "Step: 7050 / 9843, loss:0.028203, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:7101, training accuracy:1.000000\n",
      "Step: 7100 / 9843, loss:0.015961, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:7151, training accuracy:0.953125\n",
      "Step: 7150 / 9843, loss:0.094507, accuracy:0.953125\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:7201, training accuracy:0.953125\n",
      "Step: 7200 / 9843, loss:0.110768, accuracy:0.953125\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:7201, testing accuracy:0.781250\n",
      "Step: 7200 / 9843, loss:1.091756, accuracy:0.781250\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:7251, training accuracy:1.000000\n",
      "Step: 7250 / 9843, loss:0.017958, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:7301, training accuracy:0.968750\n",
      "Step: 7300 / 9843, loss:0.053767, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:7351, training accuracy:1.000000\n",
      "Step: 7350 / 9843, loss:0.003681, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:7401, training accuracy:0.968750\n",
      "Step: 7400 / 9843, loss:0.066692, accuracy:0.968750\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:7401, testing accuracy:0.906250\n",
      "Step: 7400 / 9843, loss:0.457986, accuracy:0.906250\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:7451, training accuracy:0.953125\n",
      "Step: 7450 / 9843, loss:0.075253, accuracy:0.953125\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:7501, training accuracy:1.000000\n",
      "Step: 7500 / 9843, loss:0.007115, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:7551, training accuracy:0.953125\n",
      "Step: 7550 / 9843, loss:0.204554, accuracy:0.953125\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:7601, training accuracy:0.984375\n",
      "Step: 7600 / 9843, loss:0.020217, accuracy:0.984375\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:7601, testing accuracy:0.937500\n",
      "Step: 7600 / 9843, loss:0.200514, accuracy:0.937500\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Step:7651, training accuracy:0.984375\n",
      "Step: 7650 / 9843, loss:0.021363, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:7701, training accuracy:0.953125\n",
      "Step: 7700 / 9843, loss:0.210182, accuracy:0.953125\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:7751, training accuracy:0.984375\n",
      "Step: 7750 / 9843, loss:0.043303, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:7801, training accuracy:0.968750\n",
      "Step: 7800 / 9843, loss:0.044631, accuracy:0.968750\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:7801, testing accuracy:0.937500\n",
      "Step: 7800 / 9843, loss:0.204294, accuracy:0.937500\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:7851, training accuracy:0.984375\n",
      "Step: 7850 / 9843, loss:0.034153, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:7901, training accuracy:0.968750\n",
      "Step: 7900 / 9843, loss:0.118199, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:7951, training accuracy:0.984375\n",
      "Step: 7950 / 9843, loss:0.101045, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:8001, training accuracy:0.984375\n",
      "Step: 8000 / 9843, loss:0.057492, accuracy:0.984375\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:8001, testing accuracy:0.906250\n",
      "Step: 8000 / 9843, loss:0.328645, accuracy:0.906250\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:8051, training accuracy:1.000000\n",
      "Step: 8050 / 9843, loss:0.033053, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:8101, training accuracy:0.984375\n",
      "Step: 8100 / 9843, loss:0.021424, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:8151, training accuracy:0.984375\n",
      "Step: 8150 / 9843, loss:0.103520, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:8201, training accuracy:0.968750\n",
      "Step: 8200 / 9843, loss:0.089737, accuracy:0.968750\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:8201, testing accuracy:0.937500\n",
      "Step: 8200 / 9843, loss:0.264802, accuracy:0.937500\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:8251, training accuracy:0.984375\n",
      "Step: 8250 / 9843, loss:0.028960, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:8301, training accuracy:0.984375\n",
      "Step: 8300 / 9843, loss:0.029270, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:8351, training accuracy:0.968750\n",
      "Step: 8350 / 9843, loss:0.077740, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:8401, training accuracy:0.984375\n",
      "Step: 8400 / 9843, loss:0.070597, accuracy:0.984375\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:8401, testing accuracy:0.937500\n",
      "Step: 8400 / 9843, loss:0.358421, accuracy:0.937500\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:8451, training accuracy:0.984375\n",
      "Step: 8450 / 9843, loss:0.034995, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:8501, training accuracy:0.984375\n",
      "Step: 8500 / 9843, loss:0.116789, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:8551, training accuracy:0.984375\n",
      "Step: 8550 / 9843, loss:0.030950, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:8601, training accuracy:0.968750\n",
      "Step: 8600 / 9843, loss:0.069422, accuracy:0.968750\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:8601, testing accuracy:0.875000\n",
      "Step: 8600 / 9843, loss:0.511513, accuracy:0.875000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:8651, training accuracy:0.953125\n",
      "Step: 8650 / 9843, loss:0.124450, accuracy:0.953125\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:8701, training accuracy:1.000000\n",
      "Step: 8700 / 9843, loss:0.008010, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:8751, training accuracy:0.968750\n",
      "Step: 8750 / 9843, loss:0.057976, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:8801, training accuracy:1.000000\n",
      "Step: 8800 / 9843, loss:0.006080, accuracy:1.000000\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:8801, testing accuracy:0.937500\n",
      "Step: 8800 / 9843, loss:0.427600, accuracy:0.937500\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Step:8851, training accuracy:0.984375\n",
      "Step: 8850 / 9843, loss:0.027680, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:8901, training accuracy:1.000000\n",
      "Step: 8900 / 9843, loss:0.007087, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:8951, training accuracy:1.000000\n",
      "Step: 8950 / 9843, loss:0.002915, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:9001, training accuracy:0.984375\n",
      "Step: 9000 / 9843, loss:0.028946, accuracy:0.984375\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:9001, testing accuracy:0.921875\n",
      "Step: 9000 / 9843, loss:0.204132, accuracy:0.921875\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:9051, training accuracy:0.984375\n",
      "Step: 9050 / 9843, loss:0.052504, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:9101, training accuracy:0.984375\n",
      "Step: 9100 / 9843, loss:0.041257, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:9151, training accuracy:0.984375\n",
      "Step: 9150 / 9843, loss:0.035852, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:9201, training accuracy:0.921875\n",
      "Step: 9200 / 9843, loss:0.246202, accuracy:0.921875\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:9201, testing accuracy:0.953125\n",
      "Step: 9200 / 9843, loss:0.133897, accuracy:0.953125\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:9251, training accuracy:0.968750\n",
      "Step: 9250 / 9843, loss:0.091036, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:9301, training accuracy:1.000000\n",
      "Step: 9300 / 9843, loss:0.005333, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:9351, training accuracy:1.000000\n",
      "Step: 9350 / 9843, loss:0.016322, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:9401, training accuracy:0.984375\n",
      "Step: 9400 / 9843, loss:0.082002, accuracy:0.984375\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:9401, testing accuracy:0.984375\n",
      "Step: 9400 / 9843, loss:0.124581, accuracy:0.984375\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:9451, training accuracy:1.000000\n",
      "Step: 9450 / 9843, loss:0.016338, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:9501, training accuracy:0.984375\n",
      "Step: 9500 / 9843, loss:0.018488, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:9551, training accuracy:0.984375\n",
      "Step: 9550 / 9843, loss:0.047281, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:9601, training accuracy:0.984375\n",
      "Step: 9600 / 9843, loss:0.036788, accuracy:0.984375\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:9601, testing accuracy:0.937500\n",
      "Step: 9600 / 9843, loss:0.285527, accuracy:0.937500\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:9651, training accuracy:1.000000\n",
      "Step: 9650 / 9843, loss:0.010333, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:9701, training accuracy:0.937500\n",
      "Step: 9700 / 9843, loss:0.131670, accuracy:0.937500\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:9751, training accuracy:0.984375\n",
      "Step: 9750 / 9843, loss:0.027674, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:9801, training accuracy:0.937500\n",
      "Step: 9800 / 9843, loss:0.236477, accuracy:0.937500\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:9801, testing accuracy:0.906250\n",
      "Step: 9800 / 9843, loss:0.516982, accuracy:0.906250\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    args = Arguments()\n",
    "    data = DataGenerator(args)\n",
    "    \n",
    "    # for training\n",
    "    model = TextClassificationModel(args)\n",
    "    train(data, model, args)\n",
    "    \n",
    "    \n",
    "    # after training model, testing it using whole testing data\n",
    "    # for testing\n",
    "    # model = TextClassificationModel(args, is_training=False)\n",
    "    # test(data, model, args) # predict_accuracy:0.769333\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
